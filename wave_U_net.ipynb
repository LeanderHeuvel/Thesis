{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "name": "wave-U-net.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true,
      "authorship_tag": "ABX9TyMv3hG4PMVAz8UWDmJAVfVm",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/LeanderHeuvel/Thesis/blob/main/wave_U_net.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8uvjFe0cwV5i"
      },
      "source": [
        "## Preparations\n",
        " + Free up space\n",
        " + Download repository and requirements."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NBH_FXoPCvrF",
        "outputId": "1206a66f-3420-4850-f1a9-2ad50d896d24"
      },
      "source": [
        "!rm -r \"Wave-U-Net-Pytorch\"\n",
        "!rm -rf \"/usr/local/lib/python2.7\"\n",
        "!rm -rf \"/swift\"\n",
        "!rm -rf \"/tensorflow-2.0.0\"\n",
        "!rm -rf \"/tensorflow-1.15.2\"\n",
        "!git clone https://github.com/LeanderHeuvel/Wave-U-Net-Pytorch.git\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Cloning into 'Wave-U-Net-Pytorch'...\n",
            "remote: Enumerating objects: 329, done.\u001b[K\n",
            "remote: Total 329 (delta 0), reused 0 (delta 0), pack-reused 329\u001b[K\n",
            "Receiving objects: 100% (329/329), 20.61 MiB | 37.22 MiB/s, done.\n",
            "Resolving deltas: 100% (175/175), done.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zv1dWUm-29Hf",
        "outputId": "10c00b56-39c9-4e16-ebe5-43d421c23dfe"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OITPGl13KO6k",
        "outputId": "455468a3-2a20-4a05-980f-5b3a9d470fc8"
      },
      "source": [
        "% cd ..\n",
        "% cd content/Wave-U-Net-Pytorch\n",
        "% ls"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/\n",
            "/content/Wave-U-Net-Pytorch\n",
            "\u001b[0m\u001b[01;34maudio_examples\u001b[0m/  \u001b[01;34mhdf\u001b[0m/     \u001b[01;34mmodel\u001b[0m/        README.md         test.py\n",
            "\u001b[01;34mcheckpoints\u001b[0m/     LICENSE  predict.py    requirements.txt  train.py\n",
            "\u001b[01;34mdata\u001b[0m/            \u001b[01;34mlogs\u001b[0m/    \u001b[01;34m__pycache__\u001b[0m/  Singularity       utils.py\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Y1JK3lrnQZb5"
      },
      "source": [
        "## Downloading pretrained models\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Botj7CPRQdM_",
        "outputId": "94cad08b-f911-4b6e-ce23-fb3fc789472c"
      },
      "source": [
        "!wget  -P /content/drive/MyDrive/Neurale-netwerken/Model/models.7z  -O /content/drive/MyDrive/Neurale-netwerken/Model/models.7z https://www.dropbox.com/s/r374hce896g4xlj/models.7z?dl=1\n",
        "!7z x  /content/drive/MyDrive/Neurale-netwerken/Model/models.7z -o/content/drive/MyDrive/Neurale-netwerken/Model\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content/drive/MyDrive/Neurale-netwerken/Model/models.7z: No such file or directory\n",
            "\n",
            "7-Zip [64] 16.02 : Copyright (c) 1999-2016 Igor Pavlov : 2016-05-21\n",
            "p7zip Version 16.02 (locale=en_US.UTF-8,Utf16=on,HugeFiles=on,64 bits,2 CPUs Intel(R) Xeon(R) CPU @ 2.20GHz (406F0),ASM,AES-NI)\n",
            "\n",
            "Scanning the drive for archives:\n",
            "  0M Scan /content/drive/MyDrive/Neurale-netwerken/Model/\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b                                                         \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n",
            "ERROR: No such file or directory\n",
            "/content/drive/MyDrive/Neurale-netwerken/Model/models.7z\n",
            "\n",
            "\n",
            "\n",
            "System ERROR:\n",
            "Unknown error -2147024894\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2H3f7wjEB1hX",
        "outputId": "d7db32e3-2604-4c51-aae0-12e800b356e2"
      },
      "source": [
        "Q!N"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/bin/bash: N: command not found\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QnOZJg2vB08s"
      },
      "source": [
        ""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "H15ufy1hGFga"
      },
      "source": [
        "## Install dependencies\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eyXRYnDHDcSw",
        "outputId": "c139d342-cf6c-476d-f645-38a4677ebc2a"
      },
      "source": [
        "!pip3 install -r requirements.txt\n",
        "#!apt-get install p7zip-full"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: future in /usr/local/lib/python3.6/dist-packages (from -r requirements.txt (line 1)) (0.16.0)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (from -r requirements.txt (line 2)) (1.19.4)\n",
            "Requirement already satisfied: librosa in /usr/local/lib/python3.6/dist-packages (from -r requirements.txt (line 3)) (0.6.3)\n",
            "Collecting soundfile\n",
            "  Downloading https://files.pythonhosted.org/packages/eb/f2/3cbbbf3b96fb9fa91582c438b574cff3f45b29c772f94c400e2c99ef5db9/SoundFile-0.10.3.post1-py2.py3-none-any.whl\n",
            "Collecting musdb\n",
            "  Downloading https://files.pythonhosted.org/packages/89/05/eef15f6bbb110bf9e4f53b336b23effb6bece1d8a2859741f540ad7e081c/musdb-0.3.2-py2.py3-none-any.whl\n",
            "Collecting museval\n",
            "  Downloading https://files.pythonhosted.org/packages/54/1a/448486d3619d0e091e2b7160cc5920ff4456e1f1de2b49650fe52e50107e/museval-0.3.1-py2.py3-none-any.whl\n",
            "Requirement already satisfied: h5py in /usr/local/lib/python3.6/dist-packages (from -r requirements.txt (line 7)) (2.10.0)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.6/dist-packages (from -r requirements.txt (line 8)) (4.41.1)\n",
            "Collecting torch==1.4.0\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/24/19/4804aea17cd136f1705a5e98a00618cb8f6ccc375ad8bfa437408e09d058/torch-1.4.0-cp36-cp36m-manylinux1_x86_64.whl (753.4MB)\n",
            "\u001b[K     |████████████████████████████████| 753.4MB 22kB/s \n",
            "\u001b[?25hCollecting torchvision==0.5.0\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/7e/90/6141bf41f5655c78e24f40f710fdd4f8a8aff6c8b7c6f0328240f649bdbe/torchvision-0.5.0-cp36-cp36m-manylinux1_x86_64.whl (4.0MB)\n",
            "\u001b[K     |████████████████████████████████| 4.0MB 55.4MB/s \n",
            "\u001b[?25hRequirement already satisfied: tensorboard in /usr/local/lib/python3.6/dist-packages (from -r requirements.txt (line 11)) (2.4.0)\n",
            "Requirement already satisfied: sortedcontainers in /usr/local/lib/python3.6/dist-packages (from -r requirements.txt (line 12)) (2.3.0)\n",
            "Collecting pydub\n",
            "  Downloading https://files.pythonhosted.org/packages/7b/d1/fbfa79371a8cd9bb15c2e3c480d7e6e340ed5cc55005174e16f48418333a/pydub-0.24.1-py2.py3-none-any.whl\n",
            "Requirement already satisfied: resampy>=0.2.0 in /usr/local/lib/python3.6/dist-packages (from librosa->-r requirements.txt (line 3)) (0.2.2)\n",
            "Requirement already satisfied: six>=1.3 in /usr/local/lib/python3.6/dist-packages (from librosa->-r requirements.txt (line 3)) (1.15.0)\n",
            "Requirement already satisfied: scikit-learn!=0.19.0,>=0.14.0 in /usr/local/lib/python3.6/dist-packages (from librosa->-r requirements.txt (line 3)) (0.22.2.post1)\n",
            "Requirement already satisfied: audioread>=2.0.0 in /usr/local/lib/python3.6/dist-packages (from librosa->-r requirements.txt (line 3)) (2.1.9)\n",
            "Requirement already satisfied: numba>=0.38.0 in /usr/local/lib/python3.6/dist-packages (from librosa->-r requirements.txt (line 3)) (0.48.0)\n",
            "Requirement already satisfied: scipy>=1.0.0 in /usr/local/lib/python3.6/dist-packages (from librosa->-r requirements.txt (line 3)) (1.4.1)\n",
            "Requirement already satisfied: decorator>=3.0.0 in /usr/local/lib/python3.6/dist-packages (from librosa->-r requirements.txt (line 3)) (4.4.2)\n",
            "Requirement already satisfied: joblib>=0.12 in /usr/local/lib/python3.6/dist-packages (from librosa->-r requirements.txt (line 3)) (1.0.0)\n",
            "Requirement already satisfied: cffi>=1.0 in /usr/local/lib/python3.6/dist-packages (from soundfile->-r requirements.txt (line 4)) (1.14.4)\n",
            "Collecting pyaml\n",
            "  Downloading https://files.pythonhosted.org/packages/15/c4/1310a054d33abc318426a956e7d6df0df76a6ddfa9c66f6310274fb75d42/pyaml-20.4.0-py2.py3-none-any.whl\n",
            "Collecting stempeg==0.1.8\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/29/ab/6e7362cbff21c25e99cfc3ef116057a7f9ebe6f429a44038eef82de3479d/stempeg-0.1.8-py3-none-any.whl (509kB)\n",
            "\u001b[K     |████████████████████████████████| 512kB 51.9MB/s \n",
            "\u001b[?25hRequirement already satisfied: jsonschema in /usr/local/lib/python3.6/dist-packages (from museval->-r requirements.txt (line 6)) (2.6.0)\n",
            "Requirement already satisfied: pandas>=1.0.1 in /usr/local/lib/python3.6/dist-packages (from museval->-r requirements.txt (line 6)) (1.1.5)\n",
            "Collecting simplejson\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/73/96/1e6b19045375890068d7342cbe280dd64ae73fd90b9735b5efb8d1e044a1/simplejson-3.17.2-cp36-cp36m-manylinux2010_x86_64.whl (127kB)\n",
            "\u001b[K     |████████████████████████████████| 133kB 54.8MB/s \n",
            "\u001b[?25hRequirement already satisfied: pillow>=4.1.1 in /usr/local/lib/python3.6/dist-packages (from torchvision==0.5.0->-r requirements.txt (line 10)) (7.0.0)\n",
            "Requirement already satisfied: google-auth<2,>=1.6.3 in /usr/local/lib/python3.6/dist-packages (from tensorboard->-r requirements.txt (line 11)) (1.17.2)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.6/dist-packages (from tensorboard->-r requirements.txt (line 11)) (3.3.3)\n",
            "Requirement already satisfied: grpcio>=1.24.3 in /usr/local/lib/python3.6/dist-packages (from tensorboard->-r requirements.txt (line 11)) (1.32.0)\n",
            "Requirement already satisfied: requests<3,>=2.21.0 in /usr/local/lib/python3.6/dist-packages (from tensorboard->-r requirements.txt (line 11)) (2.23.0)\n",
            "Requirement already satisfied: tensorboard-plugin-wit>=1.6.0 in /usr/local/lib/python3.6/dist-packages (from tensorboard->-r requirements.txt (line 11)) (1.7.0)\n",
            "Requirement already satisfied: werkzeug>=0.11.15 in /usr/local/lib/python3.6/dist-packages (from tensorboard->-r requirements.txt (line 11)) (1.0.1)\n",
            "Requirement already satisfied: setuptools>=41.0.0 in /usr/local/lib/python3.6/dist-packages (from tensorboard->-r requirements.txt (line 11)) (51.0.0)\n",
            "Requirement already satisfied: protobuf>=3.6.0 in /usr/local/lib/python3.6/dist-packages (from tensorboard->-r requirements.txt (line 11)) (3.12.4)\n",
            "Requirement already satisfied: wheel>=0.26; python_version >= \"3\" in /usr/local/lib/python3.6/dist-packages (from tensorboard->-r requirements.txt (line 11)) (0.36.2)\n",
            "Requirement already satisfied: google-auth-oauthlib<0.5,>=0.4.1 in /usr/local/lib/python3.6/dist-packages (from tensorboard->-r requirements.txt (line 11)) (0.4.2)\n",
            "Requirement already satisfied: absl-py>=0.4 in /usr/local/lib/python3.6/dist-packages (from tensorboard->-r requirements.txt (line 11)) (0.10.0)\n",
            "Requirement already satisfied: llvmlite<0.32.0,>=0.31.0dev0 in /usr/local/lib/python3.6/dist-packages (from numba>=0.38.0->librosa->-r requirements.txt (line 3)) (0.31.0)\n",
            "Requirement already satisfied: pycparser in /usr/local/lib/python3.6/dist-packages (from cffi>=1.0->soundfile->-r requirements.txt (line 4)) (2.20)\n",
            "Requirement already satisfied: PyYAML in /usr/local/lib/python3.6/dist-packages (from pyaml->musdb->-r requirements.txt (line 5)) (3.13)\n",
            "Requirement already satisfied: pytz>=2017.2 in /usr/local/lib/python3.6/dist-packages (from pandas>=1.0.1->museval->-r requirements.txt (line 6)) (2018.9)\n",
            "Requirement already satisfied: python-dateutil>=2.7.3 in /usr/local/lib/python3.6/dist-packages (from pandas>=1.0.1->museval->-r requirements.txt (line 6)) (2.8.1)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.6/dist-packages (from google-auth<2,>=1.6.3->tensorboard->-r requirements.txt (line 11)) (0.2.8)\n",
            "Requirement already satisfied: cachetools<5.0,>=2.0.0 in /usr/local/lib/python3.6/dist-packages (from google-auth<2,>=1.6.3->tensorboard->-r requirements.txt (line 11)) (4.2.0)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4; python_version >= \"3\" in /usr/local/lib/python3.6/dist-packages (from google-auth<2,>=1.6.3->tensorboard->-r requirements.txt (line 11)) (4.6)\n",
            "Requirement already satisfied: importlib-metadata; python_version < \"3.8\" in /usr/local/lib/python3.6/dist-packages (from markdown>=2.6.8->tensorboard->-r requirements.txt (line 11)) (3.3.0)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests<3,>=2.21.0->tensorboard->-r requirements.txt (line 11)) (3.0.4)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests<3,>=2.21.0->tensorboard->-r requirements.txt (line 11)) (2.10)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests<3,>=2.21.0->tensorboard->-r requirements.txt (line 11)) (2020.12.5)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests<3,>=2.21.0->tensorboard->-r requirements.txt (line 11)) (1.24.3)\n",
            "Requirement already satisfied: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.6/dist-packages (from google-auth-oauthlib<0.5,>=0.4.1->tensorboard->-r requirements.txt (line 11)) (1.3.0)\n",
            "Requirement already satisfied: pyasn1<0.5.0,>=0.4.6 in /usr/local/lib/python3.6/dist-packages (from pyasn1-modules>=0.2.1->google-auth<2,>=1.6.3->tensorboard->-r requirements.txt (line 11)) (0.4.8)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.6/dist-packages (from importlib-metadata; python_version < \"3.8\"->markdown>=2.6.8->tensorboard->-r requirements.txt (line 11)) (3.4.0)\n",
            "Requirement already satisfied: typing-extensions>=3.6.4; python_version < \"3.8\" in /usr/local/lib/python3.6/dist-packages (from importlib-metadata; python_version < \"3.8\"->markdown>=2.6.8->tensorboard->-r requirements.txt (line 11)) (3.7.4.3)\n",
            "Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.6/dist-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tensorboard->-r requirements.txt (line 11)) (3.1.0)\n",
            "Installing collected packages: soundfile, pyaml, stempeg, musdb, simplejson, museval, torch, torchvision, pydub\n",
            "  Found existing installation: torch 1.7.0+cu101\n",
            "    Uninstalling torch-1.7.0+cu101:\n",
            "      Successfully uninstalled torch-1.7.0+cu101\n",
            "  Found existing installation: torchvision 0.8.1+cu101\n",
            "    Uninstalling torchvision-0.8.1+cu101:\n",
            "      Successfully uninstalled torchvision-0.8.1+cu101\n",
            "Successfully installed musdb-0.3.2 museval-0.3.1 pyaml-20.4.0 pydub-0.24.1 simplejson-3.17.2 soundfile-0.10.3.post1 stempeg-0.1.8 torch-1.4.0 torchvision-0.5.0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "R_s9MA8UTQcQ"
      },
      "source": [
        "# (Optional) Training with the model"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rqO2gxpnphTl"
      },
      "source": [
        "Mount Google Drive and copy data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HNkRDjzbnME1",
        "outputId": "18eeb21b-ec6c-48f6-8301-3ea3f28a3f73"
      },
      "source": [
        "from google.colab import drive\n",
        "\n",
        "drive.mount('/content/drive')\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nJ15r9IRTWr_",
        "outputId": "bcd3b03e-8053-4efe-d3ca-e7aea81ebd6e"
      },
      "source": [
        "!python3.6 train.py --hdf_dir \"/content/drive/MyDrive/Neurale-netwerken/HDF\" --load_model \"/content/drive/MyDrive/Neurale-netwerken/Checkpoints/checkpoint_6380\" --dataset_dir \"/content/drive/MyDrive/Neurale-netwerken/musdb18\" --musdb_version \"compressed\" --cuda --checkpoint_dir \"/content/drive/MyDrive/Neurale-netwerken/Checkpoints\" --log_dir \"/content/drive/MyDrive/Neurale-netwerken/Log\""
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "python3.6: can't open file 'train.py': [Errno 2] No such file or directory\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zW0j7msHS3my"
      },
      "source": [
        "# Prediction with the model\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-b522lBSXAyR",
        "outputId": "2729280c-2b33-4852-bc18-6b78fe6a2094"
      },
      "source": [
        "cd /content/Wave-U-Net-Pytorch"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content/Wave-U-Net-Pytorch\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ETx3I8YVDt18",
        "outputId": "d295e047-f0a1-45c3-aa6b-17f46e6db68d"
      },
      "source": [
        "!python3.6 predict.py --load_model /content/drive/MyDrive/Neurale-netwerken/Model/waveunet/model --input \"/content/drive/MyDrive/Neurale-netwerken/Thesis/Anouk - converted - kort.wav\" --output \"/content/drive/MyDrive/Neurale-netwerken/Predictions\""
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Using valid convolutions with 97961 inputs and 88409 outputs\n",
            "Loading model from checkpoint /content/drive/MyDrive/Neurale-netwerken/Model/waveunet/model\n",
            "Step 132065\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8VkmWAEzCoU0"
      },
      "source": [
        "# Merging Vocals and drums"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "28jfz5YERdLA",
        "outputId": "f19b2657-9f61-44c8-e7c4-6c50683f1918"
      },
      "source": [
        "!pip install pydub"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting pydub\n",
            "  Downloading https://files.pythonhosted.org/packages/7b/d1/fbfa79371a8cd9bb15c2e3c480d7e6e340ed5cc55005174e16f48418333a/pydub-0.24.1-py2.py3-none-any.whl\n",
            "Installing collected packages: pydub\n",
            "Successfully installed pydub-0.24.1\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KBzUJbkuCv2G",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "82da5e21-5bd7-486d-d4f6-a89ba4f7ecf9"
      },
      "source": [
        "import os\n",
        "import glob\n",
        "from pydub import AudioSegment\n",
        "\n",
        "music_dir = '/content/drive/MyDrive/Neurale-netwerken/Predictions'  # Path where the songs are located\n",
        "extension_list = ('*.wav', '*.mp3')\n",
        "\n",
        "def match_target_amplitude(sound, target_dBFS):\n",
        "    change_in_dBFS = target_dBFS - sound.dBFS\n",
        "    return sound.apply_gain(change_in_dBFS)\n",
        "other = None\n",
        "bass = None\n",
        "other = {}\n",
        "bass = {}\n",
        "os.chdir(music_dir)\n",
        "for extension in extension_list:\n",
        "    for music in glob.glob(extension):\n",
        "        wav_filename = os.path.splitext(os.path.basename(music))[0] + '.wav'\n",
        "        #AudioSegment.from_file(music).export(mp3_filename, format='wav')\n",
        "        music_name_splitted = wav_filename.split(\".\")\n",
        "        basename = music_name_splitted[0]\n",
        "        if music_name_splitted[1] == \"wav_other\":\n",
        "          other[basename] = AudioSegment.from_wav(music_dir+\"/\"+wav_filename)\n",
        "        if music_name_splitted[1] == \"wav_bass\":\n",
        "          bass[basename] = AudioSegment.from_wav(music_dir+\"/\"+wav_filename)\n",
        "\n",
        "for elem in bass:\n",
        "  remix = None\n",
        "  bass_frag = bass[elem]\n",
        "  other_frag = other[elem]\n",
        "  remix = other_frag.overlay(bass_frag, position = 0)\n",
        "  file_handle = remix.export(elem+\"_other_bass.mp3\", format=\"mp3\")\n",
        "  print(\"converted \",file_handle)\n",
        "\n",
        "  # remix = other.overlay(bass, position = 0)\n",
        "  # #file_handle = remix.export(basename+\"_other_drums.mp3\", format=\"mp3\")\n",
        "  # converted.append(basename)\n",
        "  # other = None\n",
        "  # bass = None\n",
        "\n",
        "        \n",
        "# drums = AudioSegment.from_wav(\"/content/Wave-U-Net-Pytorch/audio_examples/Beatles_kort.wav_drums.wav\")\n",
        "# vocals = AudioSegment.from_wav(\"/content/Wave-U-Net-Pytorch/audio_examples/Beatles_kort.wav_vocals.wav\")\n",
        "# bass = AudioSegment.from_wav(\"/content/Wave-U-Net-Pytorch/audio_examples/Beatles_kort.wav_bass.wav\")\n",
        "\n",
        "# song = drums.overlay(vocals, position=0)\n",
        "# song2 = song.overlay(bass, position=0)\n",
        "# song_normalized = match_target_amplitude(song2,-20)\n",
        "# file_handle = song_normalized.export(\"Beatles.mp3\", format=\"mp3\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "converted  <_io.BufferedRandom name='ExcerptA_other_bass.mp3'>\n",
            "converted  <_io.BufferedRandom name='ExcerptB_other_bass.mp3'>\n",
            "converted  <_io.BufferedRandom name='Leonard Cohen, kort_other_bass.mp3'>\n",
            "converted  <_io.BufferedRandom name='Otis - converted - kort_other_bass.mp3'>\n",
            "converted  <_io.BufferedRandom name='Papermouth_kort_other_bass.mp3'>\n",
            "converted  <_io.BufferedRandom name='Anouk - converted - kort_other_bass.mp3'>\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "j1YRs3EOI7NM",
        "outputId": "db29316d-5c39-46f7-92b5-0f8343346f35"
      },
      "source": [
        "print(bass)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "{'ExcerptA': <pydub.audio_segment.AudioSegment object at 0x7f26ba3306a0>, 'ExcerptB': <pydub.audio_segment.AudioSegment object at 0x7f26badb9e80>, 'Leonard Cohen, kort': <pydub.audio_segment.AudioSegment object at 0x7f26badb9eb8>, 'Otis - converted - kort': <pydub.audio_segment.AudioSegment object at 0x7f26d5ddf240>, 'Papermouth_kort': <pydub.audio_segment.AudioSegment object at 0x7f26ba355eb8>, 'Anouk - converted - kort': <pydub.audio_segment.AudioSegment object at 0x7f26ba355f28>}\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7eAxgqPGSAvw"
      },
      "source": [
        "# Remixing music\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kKOhxV0BSDF_",
        "outputId": "d5ea3e13-51b2-4d75-94d3-eae6527570ce"
      },
      "source": [
        "import os\n",
        "import glob\n",
        "from pydub import AudioSegment\n",
        "\n",
        "music_dir = '/content/drive/MyDrive/Neurale-netwerken/Predictions'  # Path where the songs are located\n",
        "extension_list = ('*.wav', '*.mp3')\n",
        "\n",
        "def match_target_amplitude(sound, target_dBFS):\n",
        "    change_in_dBFS = target_dBFS - sound.dBFS\n",
        "    return sound.apply_gain(change_in_dBFS)\n",
        "\n",
        "other = {}\n",
        "bass = {}\n",
        "vocals = {}\n",
        "drums = {}\n",
        "os.chdir(music_dir)\n",
        "for extension in extension_list:\n",
        "    for music in glob.glob(extension):\n",
        "        wav_filename = os.path.splitext(os.path.basename(music))[0] + '.wav'\n",
        "        #AudioSegment.from_file(music).export(mp3_filename, format='wav')\n",
        "        music_name_splitted = wav_filename.split(\".\")\n",
        "        basename = music_name_splitted[0]\n",
        "        if music_name_splitted[1] == \"wav_other\":\n",
        "          other[basename] = AudioSegment.from_wav(music_dir+\"/\"+wav_filename)\n",
        "        if music_name_splitted[1] == \"wav_bass\":\n",
        "          bass[basename] = AudioSegment.from_wav(music_dir+\"/\"+wav_filename)\n",
        "        if music_name_splitted[1] == \"wav_drums\":\n",
        "          drums[basename] = AudioSegment.from_wav(music_dir+\"/\"+wav_filename)\n",
        "        if music_name_splitted[1] == \"wav_vocals\":\n",
        "          vocals[basename] = AudioSegment.from_wav(music_dir+\"/\"+wav_filename)\n",
        "  \n",
        "for elem in bass:\n",
        "  remix = None\n",
        "  #reduce volume of bass and other with - 6db! amazing combo!\n",
        "  bass_frag = bass[elem] - 6\n",
        "  other_frag = other[elem] - 6\n",
        "  drums_frag = drums[elem] + 6\n",
        "  vocals_frag = vocals[elem] + 6 \n",
        "  if elem == \"Anouk - converted - kort\":\n",
        "    ##Weird Google Drive bug, what's going on? Fixed anyway\n",
        "    print(\"helloworld\")\n",
        "    remix = other_frag.overlay(bass_frag, position = 0)\n",
        "    remix = remix.overlay(drums_frag, position = 0)\n",
        "    remix = remix.overlay(vocals_frag, position = 0)\n",
        "    file_handle = remix.export(elem+\"_remix2.wav\", format=\"wav\")\n",
        "  else:\n",
        "    remix = other_frag.overlay(bass_frag, position = 0)\n",
        "    remix = remix.overlay(drums_frag, position = 0)\n",
        "    remix = remix.overlay(vocals_frag, position = 0)\n",
        "    file_handle = remix.export(elem+\"_remix2.wav\", format=\"wav\")\n",
        "  print(\"converted BONIII \",file_handle)\n",
        "\n",
        "  # remix = other.overlay(bass, position = 0)\n",
        "  # #file_handle = remix.export(basename+\"_other_drums.mp3\", format=\"mp3\")\n",
        "  # converted.append(basename)\n",
        "  # other = None\n",
        "  # bass = None\n",
        "\n",
        "        \n",
        "# drums = AudioSegment.from_wav(\"/content/Wave-U-Net-Pytorch/audio_examples/Beatles_kort.wav_drums.wav\")\n",
        "# vocals = AudioSegment.from_wav(\"/content/Wave-U-Net-Pytorch/audio_examples/Beatles_kort.wav_vocals.wav\")\n",
        "# bass = AudioSegment.from_wav(\"/content/Wave-U-Net-Pytorch/audio_examples/Beatles_kort.wav_bass.wav\")\n",
        "\n",
        "# song = drums.overlay(vocals, position=0)\n",
        "# song2 = song.overlay(bass, position=0)\n",
        "# song_normalized = match_target_amplitude(song2,-20)\n",
        "# file_handle = song_normalized.export(\"Beatles.mp3\", format=\"mp3\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "converted BONIII  <_io.BufferedRandom name='ExcerptA_remix2.wav'>\n",
            "converted BONIII  <_io.BufferedRandom name='ExcerptB_remix2.wav'>\n",
            "converted BONIII  <_io.BufferedRandom name='Leonard Cohen, kort_remix2.wav'>\n",
            "converted BONIII  <_io.BufferedRandom name='Otis - converted - kort_remix2.wav'>\n",
            "converted BONIII  <_io.BufferedRandom name='Papermouth_kort_remix2.wav'>\n",
            "helloworld\n",
            "converted BONIII  <_io.BufferedRandom name='Anouk - converted - kort_remix2.wav'>\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "K6H7ylQGcSOk"
      },
      "source": [
        "# Evaluation\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kaKreVrneCGk"
      },
      "source": [
        "!mkdir evaluation"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0X-wqCAfhpvl",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "51fd56b6-a1c9-486b-fcd9-041d70f4cfd0"
      },
      "source": [
        "pip install r128gain"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting r128gain\n",
            "  Downloading https://files.pythonhosted.org/packages/84/06/5480490557f607fd8b73c768e7801e4faaaba3cee71d7f1e1ab5c9607bdc/r128gain-1.0.3.tar.gz\n",
            "Requirement already satisfied: crcmod>=1.7 in /usr/local/lib/python3.6/dist-packages (from r128gain) (1.7)\n",
            "Collecting ffmpeg-python~=0.2\n",
            "  Downloading https://files.pythonhosted.org/packages/d7/0c/56be52741f75bad4dc6555991fabd2e07b432d333da82c11ad701123888a/ffmpeg_python-0.2.0-py3-none-any.whl\n",
            "Collecting mutagen>=1.43\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/16/b3/f7aa8edf2ff4495116f95fd442b2a346aa55d1d46313143c8814886dbcdb/mutagen-1.45.1-py3-none-any.whl (218kB)\n",
            "\u001b[K     |████████████████████████████████| 225kB 39.0MB/s \n",
            "\u001b[?25hRequirement already satisfied: tqdm>=4.28.1 in /usr/local/lib/python3.6/dist-packages (from r128gain) (4.41.1)\n",
            "Requirement already satisfied: future in /usr/local/lib/python3.6/dist-packages (from ffmpeg-python~=0.2->r128gain) (0.16.0)\n",
            "Building wheels for collected packages: r128gain\n",
            "  Building wheel for r128gain (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for r128gain: filename=r128gain-1.0.3-cp36-none-any.whl size=23876 sha256=3ca3b3db7afa0f7ffbdea12a8cd118e82b9d8c8808c2bfbaf25e70566d0090a3\n",
            "  Stored in directory: /root/.cache/pip/wheels/e6/8d/08/7b3958e6b52839bcc4a0d27910da0f77e5b8fd3425dab3eb30\n",
            "Successfully built r128gain\n",
            "Installing collected packages: ffmpeg-python, mutagen, r128gain\n",
            "Successfully installed ffmpeg-python-0.2.0 mutagen-1.45.1 r128gain-1.0.3\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1EHy3Q9LcjVb"
      },
      "source": [
        "import musdb\n",
        "import museval\n",
        "import os\n",
        "import numpy as np\n",
        "\n",
        "def estimate_and_evaluate(track):\n",
        "    # assume mix as estimates\n",
        "    estimates = {\n",
        "        'vocals': track.audio,\n",
        "        'accompaniment': track.audio\n",
        "    }\n",
        "\n",
        "    # Evaluate using museval\n",
        "    scores = museval.eval_mus_track(\n",
        "        track, estimates, output_dir=\"evaluation/\"\n",
        "    )\n",
        "\n",
        "    # print nicely formatted and aggregated scores\n",
        "    print(scores)\n",
        "\n",
        "\n",
        "os.environ[\"MUSDB_PATH\"] = \"/content/drive/MyDrive/musdb18\"\n",
        "mus = musdb.DB() \n",
        "for track in mus:\n",
        "  print(track)\n",
        "#for track in mus:\n",
        " #   estimate_and_evaluate(track)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wdG7bcykcnap"
      },
      "source": [
        "import numpy as np\n",
        "\n",
        "\n",
        "estimates = {\n",
        "    'vocals': np.random.random(track.audio.shape),\n",
        "    'accompaniment': np.random.random(track.audio.shape)\n",
        "}\n",
        "\n",
        "print(museval.eval_mus_track(track, estimates, output_dir=\"evaluation\"))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "B_HjbL_q6GXG"
      },
      "source": [
        "np.array([])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-8AUjy7M60D1",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "144483c2-f308-4429-f62b-af3caf51bcf7"
      },
      "source": [
        "!r128gain -d \"//content/drive/MyDrive/Neurale-netwerken/Thesis/Anouk - converted - kort.wav\""
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\rAnalyzing audio loudness:   0% 0/1 [00:00<?, ? files/s]\r                                                       \r\u001b[0;33mUnhandled 'WAVE' tag format for file '//content/drive/MyDrive/Neurale-netwerken/Thesis/Anouk - converted - kort.wav'\u001b[0m\n",
            "\rAnalyzing audio loudness:   0% 0/1 [00:00<?, ? files/s]\r                                                       \rFile '//content/drive/MyDrive/Neurale-netwerken/Thesis/Anouk - converted - kort.wav': loudness = SKIPPED, sample peak = SKIPPED\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Pbb459m_Imng"
      },
      "source": [
        "# Normalize songs\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ll3mysLQ4-6q",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 232
        },
        "outputId": "a7d0cf31-8d61-45bb-de5b-f3710151a39d"
      },
      "source": [
        "import os\n",
        "import glob\n",
        "from pydub import AudioSegment\n",
        "\n",
        "music_dir = '/content/drive/MyDrive/Neurale-netwerken/Thesis'  # Path where the videos are located\n",
        "extension_list = ('*.wav', '*.mp3')\n",
        "\n",
        "def match_target_amplitude(sound, target_dBFS):\n",
        "    change_in_dBFS = target_dBFS - sound.dBFS\n",
        "    return sound.apply_gain(change_in_dBFS)\n",
        "\n",
        "os.chdir(music_dir)\n",
        "for extension in extension_list:\n",
        "    for music in glob.glob(extension):\n",
        "        mp3_filename = os.path.splitext(os.path.basename(music))[0] + '.wav'\n",
        "        #AudioSegment.from_file(music).export(mp3_filename, format='wav')\n",
        "\n",
        "        sound = AudioSegment.from_file(mp3_filename, \"wav\")\n",
        "        normalized_sound = match_target_amplitude(sound, -20.0)\n",
        "        normalized_sound.export(mp3_filename, format=\"wav\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "FileNotFoundError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-5-514887862988>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     10\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0msound\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply_gain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mchange_in_dBFS\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 12\u001b[0;31m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mchdir\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmusic_dir\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     13\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mextension\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mextension_list\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mmusic\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mglob\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mglob\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mextension\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: '/content/drive/MyDrive/Neurale-netwerken/Thesis'"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pPKpmp8PIoQE"
      },
      "source": [
        ""
      ]
    }
  ]
}